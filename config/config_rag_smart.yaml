models:
  llama3:
    base_url: "http://127.0.0.1:11434"
    temperature: 1.0
    max_tokens: 2048

embeddings:
  chunk_size: 1000
  chunk_overlap: 200


num_retrieved_docs: 3

vector_store_dir: "{PROJECT_ROOT}/chroma_db"
prompts_dir: "{PROJECT_ROOT}/prompts"
documents_dir: "{PROJECT_ROOT}/documents"
#chroma_db_dir: "{PROJECT_ROOT}/chroma_db"
